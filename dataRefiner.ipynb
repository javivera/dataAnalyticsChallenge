{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Configuración necesaria para que decouple detecte .env (donde están guardadas las configuraciones)\n",
    "from decouple import config\n",
    "from decouple import AutoConfig\n",
    "\n",
    "config = AutoConfig(search_path=os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá simplemente armamos una lista con todas las direcciones enteras de nuestros archivos csv\n",
    "# Decidí armarlo en una función por si a la hora de utilizarlo se quisiera cambiar la dirección raíz\n",
    "# Como predeterminado deje datasets que suele ser una dirección raíz común\n",
    "\n",
    "def directoryLister(rootdir = 'datasets/'):\n",
    "    filesDirs = []\n",
    "    \n",
    "    for rootdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            filesDirs.append(os.path.join(rootdir, file))\n",
    "        \n",
    "    print(filesDirs)\n",
    "    return filesDirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá armamos una lista con todos los dataframes provenientes de los csv's\n",
    "\n",
    "def dfListCreator(fileDirs):\n",
    "    dataFrames = []\n",
    "    for j in fileDirs:\n",
    "        with open(j, 'r') as f:\n",
    "            #d_reader = csv.DictReader(f)\n",
    "\n",
    "            #get fieldnames from DictReader object and store in list\n",
    "            #headers = d_reader.fieldnames\n",
    "            \n",
    "            dataFrames.append(pd.read_csv(j))\n",
    "        f.close()\n",
    "    return dataFrames\n",
    "    # I had to use the column names, because of the bug that makes some rows one column larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_checker(df,columns):\n",
    "    for j in columns:\n",
    "        if j not in df.columns:\n",
    "            print('{} no está entre las columnas'.format(j))\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La función column_checker está diseñada para evitar que un dataset malo corte el proceso y permitir así que los datasets buenos sean procesados\n",
    "# No la uso en este caso, por que no queda claro que espera Alkemy , y como solo tengo 3 datasets , terminaria perdiendo mucha información\n",
    "# Para evitar esto hice a mano los casos necesarios. Pero en un caso real, probablemente descartaría los datasets rotos, especialmente si fueran muchos\n",
    "# Dependiendo siempre de si puedo o no prescindir de la información que estos brindan\n",
    "# De todas maneras desde .env se puede elegir usar el checker o no.\n",
    "\n",
    "\n",
    "CHECKER = config('CHECKER')\n",
    "\n",
    "def columnSelector(dfList,columns, columns_alt = '[]'):\n",
    "    for j in range(0,len(dfList)):\n",
    "        dfList[j].columns = dfList[j].columns.str.lower()\n",
    "        dfList[j].columns = dfList[j].columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "        if CHECKER == True:\n",
    "            if column_checker(dfList[j],columns):\n",
    "                dfList[j] = dfList[j][columns]\n",
    "\n",
    "        else:\n",
    "            if 'domicilio' in dfList[j].columns:\n",
    "                dfList[j] = dfList[j][columns]\n",
    "\n",
    "                dfList[j].rename(columns = {'idprovincia':'id_provincia',\n",
    "                                            'iddepartamento': 'id_departamento',\n",
    "                                            'categoria':'categoria',\n",
    "                                            'cp':'codigo_postal',\n",
    "                                            'telefono':'numero_de_telefono',}, inplace = True) \n",
    "\n",
    "            elif 'direccion' in dfList[j].columns:\n",
    "                dfList[j] = dfList[j][columns_alt]\n",
    "\n",
    "                dfList[j].rename(columns = {'idprovincia':'id_provincia',\n",
    "                                            'iddepartamento': 'id_departamento',\n",
    "                                            'categoria':'categoria',\n",
    "                                            'cp':'codigo_postal',\n",
    "                                            'telefono':'numero_de_telefono',\n",
    "                                            'direccion':'domicilio'}, inplace = True)\n",
    "\n",
    "    \n",
    "\n",
    "def mailCleaner(df_list):\n",
    "    for df in df_list:\n",
    "        #df['numero_de_telefono']\n",
    "        df.loc[df['mail'].isnull() , ['mail']] = 'NULL'\n",
    "        df.loc[df['mail'] == np.nan , ['mail']] = 'NULL'\n",
    "        #df['numero_de_telefono'] = df['numero_de_telefono'].astype(float)\n",
    "        df.loc[df['web'].isnull() , ['web']] = 'NULL'\n",
    "        df.loc[df['web'] == 's/d' , ['web']] = 'NULL'\n",
    "        df.loc[df['cod_loc'].isnull() , ['cod_loc']] = 'NULL'\n",
    "        df.loc[df['id_provincia'].isnull() , ['id_provincia']] = 'NULL'\n",
    "        df.loc[df['id_departamento'].isnull() , ['id_departamento']] = 'NULL'\n",
    "        df.loc[df['categoria'].isnull() , ['categoria']] = 'NULL'\n",
    "        df.loc[df['nombre'].isnull() , ['nombre']] = 'NULL'\n",
    "        df.loc[df['localidad'].isnull() , ['localidad']] = 'NULL'\n",
    "        df.loc[df['provincia'].isnull() , ['provincia']] = 'NULL'\n",
    "        df.loc[df['domicilio'].isnull() , ['domicilio']] = 'NULL'\n",
    "        df.loc[df['codigo_postal'].isnull() , ['codigo_postal']] = 'NULL'\n",
    "        df.loc[df['numero_de_telefono'].isnull() , ['numero_de_telefono']] = 'NULL'\n",
    "        \n",
    "        df.loc[df['numero_de_telefono'] == 'nan' , ['numero_de_telefono']] = 'NULL'\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        df = df.dropna(how='all')\n",
    "#def typeConversion(df):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este pipeline, prepara los tres datasets limpiando las columnas no requeridas, basado en la primera consigna\n",
    "\n",
    "def dataPipeline():\n",
    "    \n",
    "    DATASETS_ROOT_DIR = config('DATASETS_DIR')\n",
    "\n",
    "    # Obtiene direcciones de mis archivos csv en base a mi rootdir\n",
    "    fileDirs = directoryLister(DATASETS_ROOT_DIR)\n",
    "    \n",
    "    # Crea una lista con los dataframes en base a los csv\n",
    "    df_list = dfListCreator(fileDirs)\n",
    "\n",
    "    # Procesa cada dataframe para seleccionar ciertas columnas establecidas en la configuracion .env\n",
    "    columns = ['cod_loc','idprovincia','iddepartamento','categoria','provincia','localidad','nombre','domicilio','cp','telefono','mail','web']\n",
    "    columns_alt = ['cod_loc','idprovincia','iddepartamento','categoria','provincia','localidad','nombre','direccion','cp','telefono','mail','web']\n",
    "    CHECKER = config('CHECKER')\n",
    "\n",
    "    columnSelector(df_list, columns, columns_alt)\n",
    "\n",
    "    mailCleaner(df_list)\n",
    "\n",
    "    return df_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/bibliotecas-populares/2022-April/bibliotecas-populares-29-04-2022.csv', 'datasets/museos/2022-April/museos-29-04-2022.csv', 'datasets/salas-de-cine/2022-April/salas-de-cine-29-04-2022.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cod_loc                                      2000010.0\n",
       "id_provincia                                       2.0\n",
       "id_departamento                                 2000.0\n",
       "categoria                        Bibliotecas Populares\n",
       "provincia              Ciudad Autónoma de Buenos Aires\n",
       "localidad                       Ciudad de Buenos Aires\n",
       "nombre                Biblioteca Popular 12 de Octubre\n",
       "domicilio                         Calle Arengreen 1187\n",
       "codigo_postal                                 C1405CYM\n",
       "numero_de_telefono                          49880766.0\n",
       "mail                    popular12deoctubre@hotmail.com\n",
       "web                                               NULL\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = dataPipeline()\n",
    "df_list[0].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesarCines(df):\n",
    "    # Descarta las columnas innecesarias, despues corrije la columna espacio_INCAA que tiene muchos espacios vacíos\n",
    "    # Finalmente transforma el tipo a enteros y luego cuenta cada apricion de cada columna , según la provincia\n",
    "    \n",
    "    df = df[['Provincia','Butacas','Pantallas', 'espacio_INCAA']]\n",
    "    \n",
    "    df.loc[df['espacio_INCAA'] == 'SI' , ['espacio_INCAA']] = 1\n",
    "    df.loc[df['espacio_INCAA'] == 'si' , ['espacio_INCAA']] = 1\n",
    "    df.loc[df['espacio_INCAA'] != 1 , ['espacio_INCAA']] = 0\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    df['espacio_INCAA'] = df['espacio_INCAA'].astype(int)\n",
    "    df['Butacas'] = df['Butacas'].astype(int)\n",
    "    df['Pantallas'] = df['Pantallas'].astype(int)\n",
    "\n",
    "    \n",
    "    df = df.groupby(['Provincia']).sum()\n",
    "    df = df.reset_index(level=0)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    \n",
    "    #df.set_index('provincia', inplace=True)\n",
    "    #print(df)\n",
    "    #a = df.groupby([\"Provincia\"]).count()['']\n",
    "    # print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Este pipeline prepara el datasets de cines, para ser subido a la base de datos, basado en la tercera consigna\n",
    "\n",
    "def cinesPipeline():\n",
    "    cinesDir = directoryLister('datasets/salas-de-cine')\n",
    "    cinesDf = dfListCreator(cinesDir)\n",
    "    cinesDf = procesarCines(cinesDf[-1]) # la última fecha\n",
    "    return cinesDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/salas-de-cine/2022-April/salas-de-cine-29-04-2022.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia</th>\n",
       "      <th>butacas</th>\n",
       "      <th>pantallas</th>\n",
       "      <th>espacio_incaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>92722</td>\n",
       "      <td>357</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Catamarca</td>\n",
       "      <td>3200</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chaco</td>\n",
       "      <td>2469</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chubut</td>\n",
       "      <td>2682</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>31386</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Corrientes</td>\n",
       "      <td>3370</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Córdoba</td>\n",
       "      <td>20799</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Entre Ríos</td>\n",
       "      <td>4086</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Formosa</td>\n",
       "      <td>1184</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jujuy</td>\n",
       "      <td>2277</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>La Pampa</td>\n",
       "      <td>2071</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>La Rioja</td>\n",
       "      <td>1477</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mendoza</td>\n",
       "      <td>11116</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Misiones</td>\n",
       "      <td>2177</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Neuquén</td>\n",
       "      <td>3959</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Río Negro</td>\n",
       "      <td>2474</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Salta</td>\n",
       "      <td>4665</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>San Juan</td>\n",
       "      <td>4617</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>San Luis</td>\n",
       "      <td>2601</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>1256</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Santa Fe</td>\n",
       "      <td>20131</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Santiago del Estero</td>\n",
       "      <td>2928</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tierra del Fuego</td>\n",
       "      <td>1445</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tucumán</td>\n",
       "      <td>5161</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          provincia  butacas  pantallas  espacio_incaa\n",
       "0                      Buenos Aires    92722        357             19\n",
       "1                         Catamarca     3200         12              1\n",
       "2                             Chaco     2469         14              1\n",
       "3                            Chubut     2682         10              4\n",
       "4   Ciudad Autónoma de Buenos Aires    31386        153              3\n",
       "5                        Corrientes     3370         17              1\n",
       "6                           Córdoba    20799        105              2\n",
       "7                        Entre Ríos     4086         17              2\n",
       "8                           Formosa     1184          4              1\n",
       "9                             Jujuy     2277          5              2\n",
       "10                         La Pampa     2071          6              2\n",
       "11                         La Rioja     1477         10              1\n",
       "12                          Mendoza    11116         47              2\n",
       "13                         Misiones     2177         10              2\n",
       "14                          Neuquén     3959         12              3\n",
       "15                        Río Negro     2474         10              4\n",
       "16                            Salta     4665         23              2\n",
       "17                         San Juan     4617         22              2\n",
       "18                         San Luis     2601         12              0\n",
       "19                       Santa Cruz     1256          7              2\n",
       "20                         Santa Fe    20131         79              3\n",
       "21              Santiago del Estero     2928         11              1\n",
       "22                 Tierra del Fuego     1445          6              0\n",
       "23                          Tucumán     5161         24              2"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cinesPipeline()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tablas creadas\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(serverLoader)\n",
    "import serverLoader\n",
    "serverLoader.createTables()\n",
    "serverLoader.updateTablesCine(cinesDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverLoader.updateTableDatos(df_list[0],'datos_bibliotecas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bd98636d4a20fe018e287a83db47090b6659692ee4acf3e063777fc8b0e3952"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('alkemy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
