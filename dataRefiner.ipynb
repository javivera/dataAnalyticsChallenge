{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Configuración necesaria para que decouple detecte .env (donde están guardadas las configuraciones)\n",
    "from decouple import config\n",
    "from decouple import AutoConfig\n",
    "\n",
    "config = AutoConfig(search_path=os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá simplemente armamos una lista con todas las direcciones enteras de nuestros archivos csv\n",
    "# Decidí armarlo en una función por si a la hora de utilizarlo se quisiera cambiar la dirección raíz\n",
    "# Como predeterminado deje datasets que suele ser una dirección raíz común\n",
    "\n",
    "def directoryLister(rootdir = 'datasets/'):\n",
    "\n",
    "    filesDirs = []\n",
    "\n",
    "    for rootdir, dirs, files in os.walk(rootdir):\n",
    "        \n",
    "        for file in files:\n",
    "            \n",
    "            filesDirs.append(os.path.join(rootdir, file))\n",
    "        \n",
    "    # print(filesDirs)\n",
    "    return filesDirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá armamos una lista con todos los dataframes provenientes de los csv's\n",
    "\n",
    "def dfListCreator(fileDirs):\n",
    "    dataFrames = []\n",
    "    for j in filesDirs:\n",
    "        with open(j, 'r') as f:\n",
    "            #d_reader = csv.DictReader(f)\n",
    "\n",
    "            #get fieldnames from DictReader object and store in list\n",
    "            #headers = d_reader.fieldnames\n",
    "            \n",
    "            dataFrames.append(pd.read_csv(j))\n",
    "        f.close()\n",
    "    return dataFrames\n",
    "    # I had to use the column names, because of the bug that makes some rows one column larger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_checker(df,columns):\n",
    "    for j in columns:\n",
    "        if j not in df.columns:\n",
    "            print('{} no está entre las columnas'.format(j))\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La función column_checker está diseñada para evitar que un dataset malo corte el proceso y permitir así que los datasets buenos sean procesados\n",
    "# No la uso en este caso, por que no queda claro que espera Alkemy , y como solo tengo 3 datasets , terminaria perdiendo mucha información\n",
    "# Para evitar esto hice a mano los casos necesarios. Pero en un caso real, probablemente descartaría los datasets rotos, especialmente si fueran muchos\n",
    "# Dependiendo siempre de si puedo o no prescindir de la información que estos brindan\n",
    "# De todas maneras desde .env se puede elegir usar el checker o no.\n",
    "\n",
    "\n",
    "\n",
    "def columnSelector(dfList,columns, columns_alt = '[]'):\n",
    "    for j in range(0,len(dfList)):\n",
    "        dfList[j].columns = dfList[j].columns.str.lower()\n",
    "        dfList[j].columns = dfList[j].columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "        if CHECKER == True:\n",
    "            if column_checker(dfList[j],columns):\n",
    "                dfList[j] = dfList[j][columns]\n",
    "\n",
    "        else:\n",
    "            if 'domicilio' in dfList[j].columns:\n",
    "                dfList[j] = dfList[j][columns]\n",
    "\n",
    "                dfList[j].rename(columns = {'idprovincia':'id_provincia',\n",
    "                                            'iddepartamento': 'id_departamento',\n",
    "                                            'categoria':'categoría',\n",
    "                                            'cp':'código postal',\n",
    "                                            'telefono':'número de teléfono',}, inplace = True) \n",
    "\n",
    "            elif 'direccion' in dfList[j].columns:\n",
    "                dfList[j] = dfList[j][columns_alt]\n",
    "\n",
    "                dfList[j].rename(columns = {'idprovincia':'id_provincia',\n",
    "                                            'iddepartamento': 'id_departamento',\n",
    "                                            'categoria':'categoría',\n",
    "                                            'cp':'código postal',\n",
    "                                            'telefono':'número de teléfono',\n",
    "                                            'direccion':'domicilio'}, inplace = True)\n",
    "\n",
    "    return dfList\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPipeline():\n",
    "    \n",
    "    DATASETS_ROOT_DIR = config('DATASETS_DIR')\n",
    "\n",
    "    # Obtiene direcciones de mis archivos csv en base a mi rootdir\n",
    "    fileDirs = directoryLister(DATASETS_ROOT_DIR)\n",
    "    \n",
    "    # Crea una lista con los dataframes en base a los csv\n",
    "    dfList = dfListCreator(fileDirs)\n",
    "\n",
    "    # Procesa cada dataframe para seleccionar ciertas columnas establecidas en la configuracion .env\n",
    "    columns = config(columns)\n",
    "    columns_alt = config(columns_alt)\n",
    "    CHECKER = config('CHECKER')\n",
    "\n",
    "    dfList = columnSelector(dfList, columns, columns_alt)\n",
    "\n",
    "    print(dfList[0].head())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cod_loc  id_provincia  id_departamento              categoría  \\\n",
      "0  70049060.0          70.0          70049.0  Bibliotecas Populares   \n",
      "1   2000010.0           2.0           2000.0  Bibliotecas Populares   \n",
      "2   2000010.0           2.0           2000.0  Bibliotecas Populares   \n",
      "3   2000010.0           2.0           2000.0  Bibliotecas Populares   \n",
      "4   2000010.0           2.0           2000.0  Bibliotecas Populares   \n",
      "\n",
      "                         provincia               localidad  \\\n",
      "0                         San Juan                   Rodeo   \n",
      "1  Ciudad Autónoma de Buenos Aires  Ciudad de Buenos Aires   \n",
      "2  Ciudad Autónoma de Buenos Aires  Ciudad de Buenos Aires   \n",
      "3  Ciudad Autónoma de Buenos Aires  Ciudad de Buenos Aires   \n",
      "4  Ciudad Autónoma de Buenos Aires  Ciudad de Buenos Aires   \n",
      "\n",
      "                                        nombre             domicilio  \\\n",
      "0         Biblioteca Popular Juan P. Garramuno         Santo Domingo   \n",
      "1  Biblioteca Popular Helena Larroque de Roffo          Simbrón 3058   \n",
      "2             Biblioteca Popular 12 de Octubre  Calle Arengreen 1187   \n",
      "3    Biblioteca Popular Villa Pueyrredón Norte         Cockrane 2334   \n",
      "4                   Biblioteca Popular Alberdi           Acevedo 666   \n",
      "\n",
      "  código postal número de teléfono                                   mail  web  \n",
      "0          5465                s/d                                    s/d  NaN  \n",
      "1      C1417EUD           45010078           asociacionroffo@yahoo.com.ar  NaN  \n",
      "2      C1405CYM           49880766         popular12deoctubre@hotmail.com  NaN  \n",
      "3      C1419FMD           45729107       bibliotecapueyrredon@hotmail.com  NaN  \n",
      "4      C1414DJN           47753325  bibliotecapopularalberdi@yahoo.com.ar  NaN  \n"
     ]
    }
   ],
   "source": [
    "dataPipeline()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bd98636d4a20fe018e287a83db47090b6659692ee4acf3e063777fc8b0e3952"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('alkemy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
